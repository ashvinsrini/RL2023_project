{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73680d28-70d7-44bb-9978-7774f5eebf04",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 7 - Model Based Reinforcement Learning </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Sep 4, 2023 - Nov 30, 2023</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. MCTS </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "    \n",
    "<a href='#Q1'><b>Student Question 1</b> Difficulty of the task (10 points)</a>\\\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing MCTS (30 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 2</b> MCTS phases</a>\n",
    "    \n",
    "**Total Points:** 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74a17-1c90-4f6b-90ea-d3164caf99a1",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "In this section, we will use **Monte Carlo Tree Search (MCTS)** algorithm to solve **DeepSea** environment form [Behaviour Suite for Reinforcement Learning (bsuite)](https://github.com/google-deepmind/bsuite). The environment targets the challenge of exploration and represents a N√óN grid where the agent starts in the top left and has to reach a goal in the bottom right location. At each timestep, the agent moves one row down and can choose one out of two actions. The agent observes the current location and receives a small negative reward of -0.01/N  for moving right and 0 reward for moving left. Additionally, the agent receives a reward of +1 for reaching the goal (treasure) and the episode ends after N timesteps. In this exercise, the number of rows and columns (N) is 10. \n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/deep_sea.png\" width=\"400px\">\n",
    "    <figcaption> Figure 1: Deep-Sea environment </figcaption>\n",
    "</div>\n",
    "\n",
    "## 1.1 Learning Objectives: <a id='1.1'></a>\n",
    "- Understand different phases of MCTS\n",
    "- Implement a simplified version of MCTS\n",
    "\n",
    "## 1.2 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "You don‚Äôt have to edit any other file other than ```ex7.ipynb``` to complete this exercise.\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                 # Images used in notebook\n",
    "‚îÇ   ex7_MCTS.ipynb       # Main assignment file containing tasks <---------\n",
    "‚îÇ   env.py               # Wrappers for the environment\n",
    "‚îÇ   simulator.py         # Using the exact environment as the model (simulator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54855efc-e89b-4386-938b-d6f4bf052f98",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.</b> Difficulty of the task (10 points)</h3> \n",
    "\n",
    "1.1. What is the probability of reaching the goal state (a function of N) for **DeepSea** environment? <br>\n",
    "1.2. If N is large, DQN (with the $\\epsilon$-greedy policy) usually fail to reach the goal state (in fact, N=10 is already challenging for DQN). In this case, which strategy will DQN converge to? <br>\n",
    "            \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "    üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58072844-b0c4-49f2-bf7b-b4384a4e8959",
   "metadata": {},
   "source": [
    "The DeepSea environment is a typical example of a reinforcement learning problem where an agent must learn to navigate an N√óNN√óN grid with the aim of maximizing rewards. To determine the probability of reaching the goal state, we can look at the structure of the problem and the rewards system defined.\n",
    "\n",
    "1.1. The probability of reaching the goal state in the DeepSea environment can be calculated by considering the number of correct actions the agent must take to reach the goal. Since the agent moves down one row at each timestep and can only move right or left, it needs to move right at every opportunity to reach the bottom right corner in exactly NN steps. If the choice to move right is random, then the probability pp of moving right at each decision point is 1221‚Äã because there are two actions.\n",
    "\n",
    "The probability of reaching the goal state is then pNpN, which is (12)N(21‚Äã)N, as the agent must make NN correct moves to the right.\n",
    "\n",
    "1.2. If NN is large, DQN (Deep Q-Network) with an œµœµ-greedy policy might fail to reach the goal state because the negative reward for moving right might discourage the agent from taking that action, especially if œµœµ is not properly tuned to encourage exploration. As NN increases, the likelihood of the agent randomly exploring the correct path to the goal decreases exponentially.\n",
    "\n",
    "In such cases, the DQN is likely to converge to the strategy of always moving left, because it avoids the small negative reward associated with moving right. This strategy minimizes the penalty received in each episode but also prevents the agent from reaching the goal and obtaining the larger positive reward. The agent thus settles for a suboptimal policy that maximizes its reward within the limited exploration it has conducted.\n",
    "\n",
    "For DQN to successfully learn to reach the goal in environments with large NN, enhancements to the learning algorithm or reward structure may be necessary to encourage sufficient exploration. Techniques such as reward shaping, optimistic initialization, or using algorithms specifically designed for hard-exploration problems (like MCTS) might be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce37baa-7700-4167-b96b-5e65c990a881",
   "metadata": {},
   "source": [
    "# 2. MCTS <a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081edfa-3417-44f7-9144-80cc5af076c7",
   "metadata": {},
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implement MCTS algorithm (30 points) </h3> \n",
    "\n",
    "Complete ```TODOs``` in the MCTS class below. Specifically, you need to: <br>\n",
    "1. finish the implementation of ```select_action``` method that selects the best action given the MCTS node using UCB1 exploration. <br>\n",
    "2. implement ```simulation``` method where you need to use best action to select the next node and expansion procedure of MCTS when there are no children.\n",
    "3. complete ```backpropagation``` method that updates the attributes of each node in the trajectory. <br>\n",
    "\n",
    "**Ensure that the notebook contains the average return plot.**\n",
    "\n",
    "The reference training plot is as Figure 2 (your plot might look different):\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/mcts_avg_return.png\">\n",
    "    <figcaption> Figure 2: Average episode return for MCTS on DeepSea environment </figcaption>\n",
    "</div>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11df358-d684-4d7c-b8ee-d6b3f89258a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bsuite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import BsuiteToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073067c6-6b04-4af9-954d-c1deb58fa1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### MCTS #####\n",
    "class Node(object):\n",
    "    \"\"\" A MCTS Node. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reward: float = 0.\n",
    "        self.visit_count: int = 0\n",
    "        self.done: bool = False\n",
    "        self.total_value: float = 0.  # cumulative value\n",
    "        self.children: dict = {}  # children nodes, index is the action\n",
    "\n",
    "    def expand(self, num_action: int):\n",
    "        \"\"\" Expands this node by adding cild nodes. \"\"\"\n",
    "        for action in range(num_action):\n",
    "            self.children[action] = Node()\n",
    "    \n",
    "    @property\n",
    "    def value(self):  # Q(s, a)\n",
    "        \"\"\"Returns the value of this node.\"\"\"\n",
    "        if self.visit_count:\n",
    "            return self.total_value / self.visit_count\n",
    "        return 0.\n",
    "\n",
    "    @property\n",
    "    def children_visits(self) -> np.ndarray:\n",
    "        \"\"\"Return array of visit counts of visited children.\"\"\"\n",
    "        return np.array([c.visit_count for c in self.children.values()])\n",
    "\n",
    "    @property\n",
    "    def children_values(self) -> np.ndarray:\n",
    "        \"\"\"Return array of values of visited children.\"\"\"\n",
    "        return np.array([c.value for c in self.children.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bccd58bf-c6aa-4cd9-a6a4-5170018f0fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    def __init__(self, env, discount = 1):\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount = discount\n",
    "        self.init_node = Node()\n",
    "        \n",
    "    def select_action(self, node, scale=1):\n",
    "        # TODO: implement selection phase of MCTS algorithm and return the best action.\n",
    "        # Hints:\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        #     2.1. Compute Q-value and UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "        #     2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "        #     2.3. Select the best action using results from 2.2.\n",
    "        ########## Your code starts here. ##########\n",
    "        if not node.children:\n",
    "            return np.random.randint(self.num_actions)\n",
    "\n",
    "        best_action = None\n",
    "        best_ucb1 = -np.inf\n",
    "\n",
    "        for action, child_node in node.children.items():\n",
    "            q_value = child_node.value\n",
    "            exploration_bonus = np.sqrt(np.log(node.visit_count + 1) / (child_node.visit_count + 1))\n",
    "            ucb1 = q_value + scale * exploration_bonus\n",
    "\n",
    "            if ucb1 > best_ucb1:\n",
    "                best_ucb1 = ucb1\n",
    "                best_action = action\n",
    "    \n",
    "        ########## Your code ends here. ##########\n",
    "        \n",
    "        return best_action\n",
    "\n",
    "    def simulation(self):\n",
    "        state = self.env.reset()\n",
    "        node = self.init_node\n",
    "        trajectory = [node]\n",
    "\n",
    "        while not node.done:\n",
    "            # TODO: perform simulation phase of MCTS and return the trajectory of MCTS nodes.\n",
    "            # Hints:\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            # 5. Add node to the trajectory list.\n",
    "            ########## Your code starts here. ##########\n",
    "            action = self.select_action(node)\n",
    "            next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "            if action not in node.children:\n",
    "                node.expand(self.num_actions)\n",
    "\n",
    "            node = node.children[action]\n",
    "            node.reward = reward\n",
    "            node.done = done\n",
    "            trajectory.append(node)            \n",
    "            ########## Your code ends here. ##########\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "    def backpropagation(self, trajectory):\n",
    "        ep_return = 0\n",
    "        while trajectory:\n",
    "            node = trajectory.pop()\n",
    "            # TODO: implement backpropagation phase of MCTS and return the discounted sum of rewards\n",
    "            # Hints:\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            # 2. Add node return to episode return. \n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            ########## Your code starts here. ##########\n",
    "            ep_return = self.discount * ep_return + node.reward\n",
    "            node.total_value += ep_return\n",
    "            node.visit_count += 1            \n",
    "            ########## Your code ends here. ##########\n",
    "            \n",
    "        return ep_return\n",
    "\n",
    "    def run(self, num_iteration):\n",
    "        returns = []\n",
    "        for iter in range(num_iteration):\n",
    "            trajectory = self.simulation()\n",
    "            episode_return = self.backpropagation(trajectory)\n",
    "            returns.append(episode_return)\n",
    "            \n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67408669-c97e-446b-8517-390586caae54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[97mLoaded bsuite_id: deep_sea/0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = bsuite.load_from_id('deep_sea/0')\n",
    "env = BsuiteToGymWrapper(env)\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d91f7c-db90-4d15-817a-1896fed87c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = MCTS(env)\n",
    "returns = agent.run(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82a7c24-a9b6-4806-a89c-22af633d821b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computes average of last 50 episodes\n",
    "avg_returns = [np.mean(returns[-50+i:i]) for i in range(50, num_episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11ba409-146d-4a2a-83cc-a7877c3a5126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(avg_returns, linewidth=1.2, color='b')\n",
    "plt.xlabel('Episodes', fontsize=10)\n",
    "plt.ylabel('Return', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8d5d7-d6c4-4b95-98e0-cfde0fbba0c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 2.</b> MCTS algorithm (5 points)</h3> \n",
    "Describe different phases in MCTS. Explain each one briefly in your own words.\n",
    "<br>\n",
    "<br>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a8cfe-403a-4551-beb0-f54068353527",
   "metadata": {
    "tags": []
   },
   "source": [
    "MCTS has 4 distinct phases as follows\n",
    "\n",
    "\n",
    "    Selection: Choose the most promising node in the search tree based on a balance of known value and exploration potential using the UCB formula. Continue until reaching an unexplored or partially explored node.\n",
    "\n",
    "    Expansion: Expand the selected node by creating child nodes representing unexplored actions. This ensures that all possible actions are considered for exploration.\n",
    "\n",
    "    Simulation (Rollout): Simulate a playthrough from the newly expanded node by following a policy (e.g., random or heuristic) until a terminal state is reached. Estimate the expected return from this simulation.\n",
    "\n",
    "    Backpropagation: Update the statistics (value and visit count) of all nodes in the path from the root to the selected node based on the simulation results. This aggregates information about the quality of actions and states in the search tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659d502-725a-41f7-a1ad-fac876681fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex7_MCTS.ipynb```) are answered and the relevant plots are recorded in the relevant places. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e45412-1af0-4524-baba-548e88ad4992",
   "metadata": {},
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364da21-6c7f-4c68-b35a-e308b3f1acff",
   "metadata": {},
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47684b1f-c2de-42d5-9eba-56ebe6ab4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286772-df2e-4e9d-a783-24acdcbcbbd2",
   "metadata": {},
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a89e6-b33d-4f38-b169-6e871041c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00739461-6f94-43d6-a65a-9a509d061340",
   "metadata": {},
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12a922-a3d4-4297-b1a1-e5819a946949",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f95cba-7e62-4cda-b058-8134b4daa09f",
   "metadata": {},
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "And other feedback you think is worth including. Type in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a57ceb-9879-448b-bdc8-a38af34da4f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Please use the following section to record references.\n",
    "# References <a id='4.'></a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
